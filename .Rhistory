# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
# Return data
return(data.frame(timeStamp, title, description, link, tickers, row.names = NULL))
}
# Function to pull data and format it
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
returnData <- cbind(siteName, returnData)
return(returnData)
}
#################
### PULL DATA ###
#################
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
head(aData)
aData[,"title"] <- gsub("'", "", aData[,"title"])
aData[,"description"] <- gsub("'", "", aData[,"description"])
aData[,"timeStamp"] <- GetTime(aData[,"timeStamp"])
aData <- aData[order(aData[,"timeStamp"], decreasing=TRUE), ]
print(head(aData))
print(dim(aData))
# Load packages
library(XML)
library(lubridate)
source("dbFunctions.R")
source("SourceTimeFunction.R")
########################
### ADD NOTIFICATION ###
########################
noticeText <- "Starting news collection process"
mydb = dbConnect(MySQL(), user='finance', password='nederland', host='localhost')
on.exit(dbDisconnect(mydb))
rs <- dbSendQuery(mydb, "USE finance;")
dbNotification(noticeText, 10)
dbFinDisconnect()
#################################################
### FUNCTIONS FOR PULLING AND PROCESSING DATA ###
#################################################
# Function to get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timeStampTag, titleTag, descTag, linkTag, getTicker) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
# Return data
return(data.frame(timeStamp, title, description, link, tickers, row.names = NULL))
}
# Function to pull data and format it
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
returnData <- cbind(siteName, returnData)
return(returnData)
}
#################
### PULL DATA ###
#################
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
head(aData)
####################
### PROCESS DATA ###
####################
aData[,"title"] <- gsub("'", "", aData[,"title"])
aData[,"description"] <- gsub("'", "", aData[,"description"])
aData[,"timeStamp"] <- GetTime(aData[,"timeStamp"])
aData <- aData[order(aData[,"timeStamp"], decreasing=TRUE), ]
print(head(aData))
print(dim(aData))
aData[,"timeStamp"]
dateTimeLastRecord <- "2015-08-01 14:31:47"
aData <- aData[aData[,"timeStamp"]>dateTimeLastRecord,]
aData[aData[,"timeStamp"]
aData[,"timeStamp"]
aData[,"timeStamp"]>dateTimeLastRecord
"2015-08-01 14:31:47 EDT" >  "2015-08-01 14:31:47"
"2015-08-01 14:31:47 EDT" >  "2015-08-01 14:31:46"
"2015-08-01 14:31:47 EDT" >  "2015-08-01 14:31:48"
ymd_hms(dateTimeLastRecord)
ymd_hms(dateTimeLastRecord, tz="America/New_York")
ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(1)
# dateTimeLastRecord <- "2015-08-01 14:31:47" # Debug line
aData <- aData[aData[,"timeStamp"]>ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(1),]
aData[,"timeStamp"]
dateTimeLastRecord
aData <- aData[aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(1),]
aData[,"timeStamp"]
ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(1)
aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York")
aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(30)
aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(60)
aData[,"timeStamp"]
ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(60)
aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(600)
class(  aData[,"timeStamp"] )
class(ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(600))
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
head(aData)
aData[,"title"] <- gsub("'", "", aData[,"title"])
aData[,"description"] <- gsub("'", "", aData[,"description"])
aData[,"timeStamp"] <- GetTime(aData[,"timeStamp"])
aData <- aData[order(aData[,"timeStamp"], decreasing=TRUE), ]
print(head(aData))
print(dim(aData))
aData[,"timeStamp"]
dateTimeLastRecord
class(  aData[,"timeStamp"] )
aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(1)
bData <- aData
aData <- aData[aData[,"timeStamp"] > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(30),]
aData[,"timeStamp"]
as.POSIXct(aData[,"timeStamp"])
as.POSIXct(aData[,"timeStamp"],tz="America/New_York")
aData <- aData[as.POSIXct(aData[,"timeStamp"],tz="America/New_York") > ymd_hms(dateTimeLastRecord, tz="America/New_York") + seconds(30),]
aData[,"timeStamp"]
dateTimeLastRecord
paste("Quote total: ", nrQuotesTotal, " Quote today: ", nrQuotesToday, sep="")
# Load packages
library(XML)
library(lubridate)
#source("/home/finance/Gitfin/dbFunctions.R")
source("SourceTimeFunction.R")
#################################################
### FUNCTIONS FOR PULLING AND PROCESSING DATA ###
#################################################
# Function to get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timeStampTag, titleTag, descTag, linkTag, getTicker) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
# Return data
return(data.frame(timeStamp, title, description, link, tickers, row.names = NULL))
}
# Function to pull data and format it
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
returnData <- cbind(siteName, returnData)
return(returnData)
}
#################
### PULL DATA ###
#################
# Create space to save data
aData <- c()
xmltop <- GetTop("http://www.ft.com/rss/markets")
xmltop
# Financial Times
xmltop <- GetTop("http://www.ft.com/rss/markets")
newsData <- ProcessTop("ft.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "guid", FALSE)
aData <- rbind(aData, newsData)
head(aData)
xmltop <- GetTop("http://www.marketwatch.com/rss/")
xmltop
xmltop
xmltop <- GetTop("http://www.marketwatch.com/rss/")
xmltop <- GetTop("http://feeds.marketwatch.com/marketwatch/realtimeheadlines?format=xml")
xmltop
GetTop("http://www.marketwatch.com/rss/topstories")
GetTop("http://feeds.marketwatch.com/marketwatch/topstories/")
xmltop <- GetTop("http://www.marketwatch.com/rss/newsfinder/AllMarketWatchNews/?p=type&pv=Stocks%20to%20Watch&t=Stocks%20to%20Watch&dist=sr_rss")
newsData <- ProcessTop("xxx", xmltop, "//rss/channel/item", "pubDate", "title", "description", "guid", FALSE)
xmltop
newsData <- ProcessTop("marketwatch.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
head(newsData)
xmltop <- GetTop("http://www.marketwatch.com/rss/newsfinder/")
xmltop <- GetTop("http://www.marketwatch.com/rss/newsfinder/")
newsData <- ProcessTop("marketwatch.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
head(newsData)
fix(newsData)
xmltop <- GetTop(""feed/http://www.forbes.com/markets/index.xml"")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
xmltop <- GetTop("feed/http://www.forbes.com/markets/index.xml")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
head(newsData)
xmltop <- GetTop("feed/http://www.forbes.com/markets/index.xml")
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
head(newsData)
xmltop
View(newsData)
View(newsData)
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
# Load packages
library(XML)
library(lubridate)
#source("/home/finance/Gitfin/dbFunctions.R")
source("SourceTimeFunction.R")
#################################################
### FUNCTIONS FOR PULLING AND PROCESSING DATA ###
#################################################
# Function to get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timeStampTag, titleTag, descTag, linkTag, getTicker) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
# Return data
return(data.frame(timeStamp, title, description, link, tickers, row.names = NULL))
}
# Function to pull data and format it
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
returnData <- cbind(siteName, returnData)
return(returnData)
}
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
head(newsData)
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
xmltop
ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
nodes <- getNodeSet(xmltop,"//rss/channel/item")
fix(xmltop)
xmltop
xmltop <- GetTop("http://www.ft.com/rss/markets")
xmltop
ProcessTop("ft.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "guid", FALSE)
getNodeSet(xmltop,"//rss/channel/item")
nodes
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
xmltop
ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
nodes <- getNodeSet(xmltop,"//rss/channel/item")
head(newsData)
nodes
node <- nodes[[1]]
node
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
nData
names(nData) <- gsub(".text", "", names(nData))
nData
nData
timeStampTag <- "pubDate"
titleTag <- "title"
descTag <- "description"
linkTag <- "link"
getTicker <- FALSE
nData
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
xpath
xpath <- "//rss/channel/item"
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
ProcessTop <- function(siteName, xmltop, xpath, timeStampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timeStampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
returnData <- cbind(siteName, returnData)
return(returnData)
}
timeStampTag
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timeStampTag, titleTag, descTag, linkTag, getTicker)
nodeData
nodeData <- lapply(nodes, GetNodeDetails, timeStampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData), stringsAsFactors = FAlSE)
?lappy
?lapply
lapply(nodeData, names)
node <- nodes[[1]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
timeStampTag <- "pubDate"
titleTag <- "title"
descTag <- "description"
linkTag <- "link"
getTicker <- FALSE
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
node <- nodes[[2]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
timeStampTag <- "pubDate"
titleTag <- "title"
descTag <- "description"
linkTag <- "link"
getTicker <- FALSE
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
node <- nodes[[2]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
node <- nodes[[1]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
nodes[[1]]
nodes[[2]]
xmlSApply(node, function(x) xmlSApply(x, xmlValue))
node <- nodes[[2]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
unlist(nData)
node <- nodes[[1]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData
node <- nodes[[2]]
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData <- unlist(nData)
nData
timeStampTag <- "pubDate"
titleTag <- "title"
descTag <- "description"
linkTag <- "link"
getTicker <- FALSE
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
# Function to extract data from node
GetNodeDetails <- function(node, timeStampTag, titleTag, descTag, linkTag, getTicker) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
nData <- unlist(nData)
# Get elements
timeStamp <- nData[timeStampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- paste(unique(tickers),collapse=",")
} else {
tickers <- NA
}
# Return data
return(data.frame(timeStamp, title, description, link, tickers, row.names = NULL))
}
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
fix(newsData)
newsData
xmltop <- GetTop("http://www.forbes.com/markets/index.xml")
newsData <- ProcessTop("forbes.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
fix(newsData)
