?fetch
??
fetch
library(RMySQL)
?fetch
library(quantmod)
library(quantmod)
?getQuote
selectSymbols <- c("AAPL", "ADBE", "ADI", "ADP", "ADSK", "AKAM", "ALTR", "ALXN", "AMAT", "AMGN", "AMZN")
quoteData <- getQuote(selectSymbols)
quoteData
names(quoteData)
quoteData[,"ticker"] <- row.names(quoteData)
head(quoteData)
print(qData[,c("ticker", "Trade Time", "Last")])
qData <- getQuote(selectSymbols)
qData[,"ticker"] <- row.names(qData)
print(qData[,c("ticker", "Trade Time", "Last")])
query <- paste("INSERT INTO prices (ticker, price)
VALUES ('", selectSymbols[shareNr], "', '", quoteData[shareNr, "Last"], "');", sep="")
shareNr <- 1
query <- paste("INSERT INTO prices (ticker, price)
VALUES ('", selectSymbols[shareNr], "', '", quoteData[shareNr, "Last"], "');", sep="")
query
head(qData)
# Load packages
library(XML)
# Function get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timestampTag, titleTag, descTag, linkTag) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timestampTag]
title <- nData[titleTag]
description <- nData[descTag]
link <- nData[linkTag]
# Tickers
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- unique(tickers)
tickers <- paste(tickers,collapse=",")
# Create data frame to return
returnData <- data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
# Return data frame
return(returnData)
}
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag)
returnData <- as.data.frame(do.call(rbind, nodeData))
returnData <- cbind(siteName, returnData)
return(returnData)
}
allNewsData <- c()
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link")
allNewsData <- rbind(allNewsData, newsData)
allNewsData
# Load packages
library(XML)
# Function get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timestampTag, titleTag, descTag, linkTag) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timestampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- unique(tickers)
tickers <- paste(tickers,collapse=",")
# Create data frame to return
returnData <- data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
# Return data frame
return(returnData)
}
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag)
returnData <- as.data.frame(do.call(rbind, nodeData))
returnData <- cbind(siteName, returnData)
return(returnData)
}
allNewsData <- c()
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", NA)
allNewsData <- rbind(allNewsData, newsData)
allNewsData
# Load packages
library(XML)
# Function get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timestampTag, titleTag, descTag, linkTag) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timestampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- unique(tickers)
tickers <- paste(tickers,collapse=",")
} else {
tickers <- NA
}
# Create data frame to return
returnData <- data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
# Return data frame
return(returnData)
}
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData))
returnData <- cbind(siteName, returnData)
return(returnData)
}
allNewsData <- c()
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
allNewsData <- rbind(allNewsData, newsData)
# Function get data from url
GetTop <- function(url) {
con = url(url); sourceCode = readLines(con); close(con)
xmlfile <- xmlTreeParse(sourceCode)
xmltop = xmlRoot(xmlfile)
return(xmltop)
}
# Function to extract data from node
GetNodeDetails <- function(node, timestampTag, titleTag, descTag, linkTag, getTicker) {
# Process data
nData <- xmlSApply(node, function(x) xmlSApply(x, xmlValue))
names(nData) <- gsub(".text", "", names(nData))
# Get elements
timeStamp <- nData[timestampTag]
title <- nData[titleTag]
if(!is.na(descTag)) { description <- nData[descTag] } else { description <- NA }
if(!is.na(linkTag)) { link <- nData[linkTag] } else { link <- NA }
# Tickers
if(getTicker) {
tData <- as.data.frame(nData, stringsAsFactors=FALSE)
tickers <- grep("^([A-Z]{1,5})$", tData[,1], value=TRUE)
tickers <- unique(tickers)
tickers <- paste(tickers,collapse=",")
} else {
tickers <- NA
}
# Create data frame to return
returnData <- data.frame(timeStamp, title, description, link, tickers, row.names = NULL)
# Return data frame
return(returnData)
}
ProcessTop <- function(siteName, xmltop, xpath, timestampTag, titleTag, descTag, linkTag, getTicker) {
nodes <- getNodeSet(xmltop, xpath)
nodeData <- lapply(nodes, GetNodeDetails, timestampTag, titleTag, descTag, linkTag, getTicker)
returnData <- as.data.frame(do.call(rbind, nodeData))
returnData <- cbind(siteName, returnData)
return(returnData)
}
allNewsData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", "title", "link", TRUE)
allNewsData <- rbind(allNewsData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
allNewsData <- rbind(allNewsData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
allNewsData <- rbind(allNewsData, newsData)
fix(allNewsData)
fix(allNewsData)
allNewsData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
allNewsData <- rbind(allNewsData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
allNewsData <- rbind(allNewsData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
allNewsData <- rbind(allNewsData, newsData)
fix(allNewsData)
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
names(aData)
aData[,"timeStamp"]
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
class(aData[,"timeStamp"])
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
class(aData[,"timeStamp"])
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
class(aData[,"timeStamp"])
class(aData[,"title"])
names(aData)
# Create non-factor data
aData[,"siteName"] <- levels(aData[,"siteName"])[aData[,"siteName"]]
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
aData[,"title"] <- levels(aData[,"title"])[aData[,"title"]]
aData[,"description"] <- levels(aData[,"description"])[aData[,"description"]]
aData[,"link"] <- levels(aData[,"link"])[aData[,"link"]]
aData[,"tickers"] <- levels(aData[,"tickers"])[aData[,"tickers"]]
sys.Date()
sys.date()
Sys.date()
Sys.time()
aData[,"timeStamp"]
names(aData)
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
aData[,"siteName"] <- levels(aData[,"siteName"])[aData[,"siteName"]]
names(aData)
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
names(aData)
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
####################################
### SUBSET DATA RECENT NEWS ONLY ###
####################################
# Create non-factor data
aData[,"siteName"] <- levels(aData[,"siteName"])[aData[,"siteName"]]
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
aData[,"title"] <- levels(aData[,"title"])[aData[,"title"]]
aData[,"description"] <- levels(aData[,"description"])[aData[,"description"]]
aData[,"link"] <- levels(aData[,"link"])[aData[,"link"]]
aData[,"tickers"] <- levels(aData[,"tickers"])[aData[,"tickers"]]
fix(aData)
aData[1,"timeStamp"]
class(aData[1,"timeStamp"])
as.Data
?as.Date
as.Date(aData[1,"timeStamp"])
as.Date(aData[20,"timeStamp"])
as.Date(aData[30,"timeStamp"])
as.Date(aData[50,"timeStamp"])
dim(aData)
as.Date(aData[70,"timeStamp"])
aData[70,"timeStamp"]
?as.Date
?as.POSIXct
myDate <- aData[70,"timeStamp"]
myDate
as.POSIXct(myDate, "EDT")
myDate
myDate <- "Tue, 28 Jul 2015 21:18:59"
as.POSIXct(myDate, "EDT")
myDate <- "28 Jul 2015 21:18:59"
as.POSIXct(myDate, "EDT")
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Create space to save data
aData <- c()
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
head(newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
head(newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
head(newsData)
head(newsData)
myDate <- aData[1,"timeStamp"])
# SEEKING ALPHA
xmltop <- GetTop("http://seekingalpha.com/feed.xml")
newsData <- ProcessTop("seekingalpha.com", xmltop, "//channel/item", "pubDate", "title", NA, "link", TRUE)
aData <- rbind(aData, newsData)
# Motley Fool
xmltop <- GetTop("http://www.fool.com/feeds/index.aspx?id=foolwatch&format=rss2")
newsData <- ProcessTop("fool.com", xmltop, "//channel/item", "pubDate", "title", "description", "guid", TRUE)
aData <- rbind(aData, newsData)
# Wall Street Journal
xmltop <- GetTop("http://www.wsj.com/xml/rss/3_7031.xml")
newsData <- ProcessTop("wsj.com", xmltop, "//rss/channel/item", "pubDate", "title", "description", "link", FALSE)
aData <- rbind(aData, newsData)
####################################
### SUBSET DATA RECENT NEWS ONLY ###
####################################
# Create non-factor data
aData[,"siteName"] <- levels(aData[,"siteName"])[aData[,"siteName"]]
aData[,"timeStamp"] <- levels(aData[,"timeStamp"])[aData[,"timeStamp"]]
aData[,"title"] <- levels(aData[,"title"])[aData[,"title"]]
aData[,"description"] <- levels(aData[,"description"])[aData[,"description"]]
aData[,"link"] <- levels(aData[,"link"])[aData[,"link"]]
aData[,"tickers"] <- levels(aData[,"tickers"])[aData[,"tickers"]]
myDate <- aData[1,"timeStamp"])
myDate <- aData[1,"timeStamp"]
myDate <- aData[1,"timeStamp"]
myDate
as.POSIXct(myDate)
myDate <- "28 Jul 2015 21:18:59"
as.POSIXct(myDate)
as.Date(myDate)
?strptime
activate <- c("AAPL", "ADBE", "ADI", "ADP", "ADSK", "AKAM", "ALTR", "ALXN", "AMAT", "AMGN", "AMZN",
"ATVI", "AVGO", "BBBY", "BIDU", "BIIB", "BRCM", "CA", "CELG", "CERN", "CHKP", "CHRW",
"CHTR", "CMCSA", "COST", "CSCO", "CTRX", "CTSH", "CTXS", "DISCA", "DLTR", "DTV", "EBAY",
"EQIX", "ESRX", "EXPD", "EXPE", "FAST", "FB", "FFIV", "FISV", "FOSL", "FOXA", "GILD",
"GMCR", "GOLD", "GOOG", "GRMN", "HSIC", "INTC", "INTU", "ISRG", "KLAC", "KRFT", "LBTYA",
"LINTA", "LLTC", "LMCA", "MAT", "MCHP", "MDLZ", "MNST", "MSFT", "MU", "MXIM", "MYL",
"NFLX", "NTAP", "NUAN", "NVDA", "ORLY", "PAYX", "PCAR", "PCLN", "QCOM", "REGN", "ROST",
"SBAC", "SBUX", "SHLD", "SIAL", "SIRI", "SNDK", "SPLS", "SRCL", "STX", "SYMC", "TSLA",
"TXN", "VIAB", "VOD", "VRSK", "VRTX", "WDC", "WFM", "WYNN", "XLNX", "XRAY", "YHOO")
activate <- paste(c("'",paste(activate, collapse="', '"),"'"), collapse="")
print(paste("Activating: ", activate, sep=""))
query <- paste("UPDATE ticker SET isActive = 1 WHERE symbol in (", activate, ");", sep="")
query
